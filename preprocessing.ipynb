{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bK99c9rNK1yn",
    "outputId": "92e16541-0b33-4e76-955f-a9ae858f031f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('df_Req_original.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Pe3jsm7dJCR"
   },
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilt1tbjxK59z",
    "outputId": "a6c37155-c146-4c88-83f4-566c8cd9b295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n",
      "(23313, 4)\n",
      "(23313, 3)\n",
      "Index(['Unnamed: 0', 'Text', 'Estimate', 'Cleaned'], dtype='object')\n",
      "   Unnamed: 0                                               Text  Estimate  \\\n",
      "0       23009  add ca against object literals in function inv...         1   \n",
      "1       23013  update branding for appcelerator plugin to app...         1   \n",
      "2       23003  create new json schema for sdk team{html}<div>...         1   \n",
      "\n",
      "                                             Cleaned  \n",
      "0  add ca against object literals in function inv...  \n",
      "1  update branding for appcelerator plugin to app...  \n",
      "2  create new json schema for sdk team create jso...  \n",
      "(23313,)\n"
     ]
    }
   ],
   "source": [
    "# Text cleaning\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "\n",
    "df_Req=pd.read_csv('df_Req_original.csv')\n",
    "##df_Req=pd.read_csv('df123.csv', sep = ',', delimiter = ',')\n",
    "\n",
    "df_Req.sort_values(by='File_ID',inplace=True)\n",
    "df_Req.set_index('File_ID')\n",
    "\n",
    "print(df_Req.shape)\n",
    "\n",
    "df_Est=pd.read_csv('estiDeep.data', names=['Estimate'])\n",
    "#df_Est=pd.read_csv('estiDeepPre.data', names=['Estimate'])\n",
    "#df_Est=pd.read_csv('estiDeepProj.data', names=['Estimate'])\n",
    "\n",
    "df_Est.insert(0, 'Est_ID', range(0, len(df_Est)))\n",
    "\n",
    "\n",
    "\n",
    "# Merging requirements and efforts estimates dataframes\n",
    "# df_Est contains storypoints software effort estimatives\n",
    "\n",
    "df_Merge=pd.merge(df_Req, df_Est, how='inner', on=None, left_on='File_ID', right_on='Est_ID',\n",
    "         left_index=False, right_index=False, sort=False,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "\n",
    "# Removing unused columns\n",
    "\n",
    "df_Merge.drop(columns =['Filename','File_ID','Est_ID'], inplace=True)\n",
    "df=df_Merge\n",
    "\n",
    "# Visualizing merged dataframe\n",
    "\n",
    "print(df_Merge.head(3))\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Cleaning method - removes tags like < div> ,< p> , < code>, < pre> ...etc which are present in requirements texts\n",
    "\n",
    "def CleanText(Text):\n",
    "    Text = re.sub(r'html',' ',Text)\n",
    "    Text = re.sub(r'{html}',' ',Text)\n",
    "    Text = re.sub(r'<div>',' ',Text)\n",
    "    Text = re.sub(r'<p>',' ',Text)\n",
    "    Text = re.sub(r'<pre>',' ',Text)\n",
    "    Text = re.sub(r'<code>',' ',Text)\n",
    "    Text = re.sub(r'html',' ',Text)\n",
    "    Text = re.sub(r'< div>',' ',Text)\n",
    "    Text = re.sub(r'<div>',' ',Text)\n",
    "    Text = re.sub(r'< p>',' ',Text)\n",
    "    Text = re.sub(r'<p>',' ',Text)\n",
    "    Text = re.sub(r'< pre>',' ',Text)\n",
    "    Text = re.sub(r'< code>',' ',Text)\n",
    "    Text = re.sub(r'< code>',' ',Text)\n",
    "    \n",
    "    # Uses str lib to make an additional cleaning of punctuation and digits (we considered irrelevant characters)\n",
    "    trans_punct = str.maketrans('', '', string.punctuation)\n",
    "    trans_digit = str.maketrans('', '', string.digits)\n",
    "    Text = Text.translate(trans_punct)\n",
    "    Text = Text.translate(trans_digit)\n",
    "    Text = Text.lower()\n",
    "    \n",
    "    # additional pre-processing (text strip, and tokenizing)\n",
    "    Text = Text.strip() # remoção de espaços em branco\n",
    "    word_tokens = word_tokenize(Text) # tokenização do texto\n",
    "    Text = ' '.join(word_tokens)\n",
    "    return Text\n",
    "\n",
    "df['Cleaned']= df['Text'].apply(CleanText)\n",
    "print(df.columns)\n",
    "\n",
    "# Verificando os dados\n",
    "print(df.head(3))\n",
    "\n",
    "# df contains the added columns: \"Est_ID\" which contains estimate, \"Cleaned\" which contains the cleaned requirement.\n",
    "df.to_csv('df_Req_Final.csv', sep= ',', index = None)\n",
    "\n",
    "print(df['Cleaned'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNYjBpunKA6K"
   },
   "source": [
    "# getting repo names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NC2VAslnKAD8",
    "outputId": "8cd3b357-2a3d-413d-f053-1460e7427690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/17 files in folder\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "filenames = glob.glob('repos/*.csv')\n",
    "print(len(filenames),end='/')\n",
    "print(len(os.listdir('repos/')),end=' files in folder\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CK6DEUXmKRXr",
    "outputId": "17d3d412-a274-4b8a-bc51-26aebd0241cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 arquivos lidos\n",
      "\n",
      "23313 requisitos\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "for filename in filenames:\n",
    "  df_aux = pd.read_csv(filename)\n",
    "  df_aux['Filename'] = os.path.basename(filename)\n",
    "  # print(df_aux['Filename'])\n",
    "  data.append(df_aux)\n",
    "print(len(data), 'readed files',end='\\n\\n')\n",
    "print(sum(x.shape[0] for x in data), 'requirements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QiGIoHmMiwq",
    "outputId": "d6401775-400b-44fe-e75b-95fd274ffd91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23313, 5)\n",
      "(23313, 5)\n"
     ]
    }
   ],
   "source": [
    "df_Req = pd.concat(data,ignore_index=True)\n",
    "print(df_Req.shape)\n",
    "df_Req.dropna()\n",
    "print(df_Req.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbpBBgmBWAWk",
    "outputId": "d577725c-b373-492f-e654-fd3732343207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        HDFS ItemWriterBase integration of core HDFS w...\n",
       "1        HDFS Core writing helper classesSimple file wr...\n",
       "2                                                      NaN\n",
       "3        Tuple data structureThe tuple data structure s...\n",
       "4        Syslog IngestionHave a syslog.xml config file ...\n",
       "                               ...                        \n",
       "23308    Aptana Studio 3 gets killed after scrolling or...\n",
       "23309    Issue configuring Bitnami Django stack with Ap...\n",
       "23310    Syntax Error incorrectly reportedThe following...\n",
       "23311    Aptana Fails to launch on OS X El Capitan (10....\n",
       "23312    InstallDuring execution of Aptana_Studio_3_Set...\n",
       "Name: Text, Length: 23313, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Req['title'] = df_Req['title'].dropna()\n",
    "df_Req['description'] = df_Req['description'].dropna()\n",
    "df_Req['Text']= df_Req['title']+df_Req['description']\n",
    "df_Req['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpwcTs5eW6hA"
   },
   "outputs": [],
   "source": [
    "def na_prof(x):\n",
    "  if(type(x)==float):\n",
    "    return ''\n",
    "  return x\n",
    "df_Req['description'] = df_Req['description'].apply(lambda x: na_prof(x))\n",
    "df_Req['title'] = df_Req['title'].apply(lambda x: na_prof(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkek4qnmX6Jd"
   },
   "outputs": [],
   "source": [
    "df_Req['Text']=df_Req['title']+''+df_Req['description']\n",
    "df_Req['Text']=df_Req['Text'].apply(lambda x: x.lower())\n",
    "df_Req.head(3)\n",
    "teste = df_Req['Text'].iloc[:].values"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

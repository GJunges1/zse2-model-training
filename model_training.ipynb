{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset (embeddings and estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1X3xyTcZ7TcG",
    "outputId": "e0119c6b-1c62-43f1-c9a1-07855770711e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23313,)\n",
      "(23313,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('df_All_Embeddings.pkl')\n",
    "\n",
    "print(df['all_embeddings'].shape)\n",
    "print(df['Estimate'].shape)\n",
    "\n",
    "# criando datasets X e y (ver se tem label repositorio no df_Req, se não tiver criar) # TODO remover\n",
    "X = df['all_embeddings'].iloc[:].values\n",
    "y = df['Estimate'].iloc[:].values\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuing from where you stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tT1RhAzKG3Dh",
    "outputId": "c4c70009-7ffc-4b9b-eb91-5d0f39780d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resuming from:\n",
      "{'mae': [3.8671381, 3.575684, 3.5730035, 3.4315414, 3.4607165, 3.912162], 'mse': [80.061966, 56.81785, 59.274582, 55.22547, 54.236168, 73.2315], 'mdae': [1.9161946, 1.9571185, 1.7877096, 1.8260198, 1.9114883, 1.9148998], 'max_error': [103.7653, 96.10432, 88.33195, 88.686386, 94.3574, 93.76645], 'r2_score': [0.31510945289217973, 0.37313219625814975, 0.4130561554123663, 0.38604373521737634, 0.4353173485532321, 0.353372377238224]}\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Note: This part of the notebook is due to I haved stopped the experiment run before its end,\n",
    "# and continued from a specific iteration\n",
    "\n",
    "# If your intent is to run the intire experiment at once, ignore this code frame, and set N to 0\n",
    "# in the fit function, in the model class, bellow.\n",
    "\n",
    "partial_results = [{'mae': 3.8671381, 'mse': 80.061966, 'mdae': 1.9161946, 'max_error': 103.7653, 'r2_score': 0.31510945289217973},\n",
    "{'mae': 3.575684, 'mse': 56.81785, 'mdae': 1.9571185, 'max_error': 96.10432, 'r2_score': 0.37313219625814975},\n",
    "{'mae': 3.5730035, 'mse': 59.274582, 'mdae': 1.7877096, 'max_error': 88.33195, 'r2_score': 0.4130561554123663},\n",
    "{'mae': 3.4315414, 'mse': 55.22547, 'mdae': 1.8260198, 'max_error': 88.686386, 'r2_score': 0.38604373521737634},\n",
    "{'mae': 3.4607165, 'mse': 54.236168, 'mdae': 1.9114883, 'max_error': 94.3574, 'r2_score': 0.4353173485532321},\n",
    "{'mae': 3.912162, 'mse': 73.2315, 'mdae': 1.9148998, 'max_error': 93.76645, 'r2_score': 0.353372377238224}\n",
    "]\n",
    "acc_vector = {\n",
    "      'mae': [],\n",
    "      'mse': [],\n",
    "      'mdae': [],\n",
    "      'max_error': [],\n",
    "      'r2_score': [],\n",
    "  }\n",
    "for partial_i in partial_results:\n",
    "  for key in partial_i.keys():\n",
    "    acc_vector[key].append(partial_i[key])\n",
    "\n",
    "print('resuming from:',acc_vector,'-----------------------------\\n',sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "EwpnfaStQRF6",
    "outputId": "9681e52f-68a6-443a-8cb0-de78a5db4451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created Issue Training status 0\n",
      "\n",
      "2884 models will be fitted\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "[STARTED] OUTER_CV 7/10\n",
      "\n",
      "Current parameter configuration being tested [1/72]:\n",
      "{'n1': 512, 'n2': 512, 'n3': 512, 'lr': 0.01, 'batch_size': 64, 'beta_1': 0.99, 'beta_2': 0.9}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r1it [01:24, 84.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[] ; []\n",
      "INNER_CV 1/10 concluded\n",
      "66/66 [==============================] - 0s 7ms/step\n",
      "\n",
      "[] ; []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2it [02:36, 76.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INNER_CV 2/10 concluded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2it [02:41, 80.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6aa0c44d69a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    221\u001b[0m                  \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                  \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                  k=10)\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n------------------------------------------\\nNESTED CV RESULTS:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6aa0c44d69a7>\u001b[0m in \u001b[0;36mnested\u001b[0;34m(X, y, config, n_iter, k)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m           \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'X_valid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_valid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test_i\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m           \u001b[0mmodel_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMyEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m           \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m           \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdesNaNify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6aa0c44d69a7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y, X_valid, y_valid)\u001b[0m\n\u001b[1;32m     78\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                      verbose=0)\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m-> 2452\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m       cache_key, cache_key_deletion_observer = function_context.make_cache_key(\n\u001b[0;32m-> 2677\u001b[0;31m           (args, kwargs))\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m       cache_key, cache_key_deletion_observer = function_context.make_cache_key(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function_context.py\u001b[0m in \u001b[0;36mmake_cache_key\u001b[0;34m(args, include_tensor_ranks_only)\u001b[0m\n\u001b[1;32m    129\u001b[0m       include_tensor_ranks_only)\n\u001b[1;32m    130\u001b[0m   function_signature = trace_type.make_function_signature(\n\u001b[0;32m--> 131\u001b[0;31m       args, signature_context)\n\u001b[0m\u001b[1;32m    132\u001b[0m   return function_cache.FunctionCacheKey(\n\u001b[1;32m    133\u001b[0m       \u001b[0mfunction_signature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36mmake_function_signature\u001b[0;34m(function_args, signature_context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mTraceType\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m   \"\"\"\n\u001b[0;32m--> 154\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_trace_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/core/function/trace_type/signature_builder.py\u001b[0m in \u001b[0;36mcreate_trace_type\u001b[0;34m(obj, context)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \"\"\"\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupportsTracingProtocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_tracing_type__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/typing_extensions.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    603\u001b[0m                        (not callable(getattr(cls, attr, None)) or\n\u001b[1;32m    604\u001b[0m                         getattr(instance, attr) is not None)\n\u001b[0;32m--> 605\u001b[0;31m                        for attr in _get_protocol_attrs(cls)):\n\u001b[0m\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, r2_score, max_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# from joblib import Parallel\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import numpy.ma as ma\n",
    "import math\n",
    "\n",
    "def desNaNify(x):\n",
    "  if math.isnan(x):\n",
    "    return 9999 # retorna um número grande ao invés de nan, para não dar erro no mse\n",
    "  return x\n",
    "\n",
    "class MyEstimator(BaseEstimator):\n",
    "  model=None\n",
    "  \n",
    "  def __init__(self, n1 = 256, n2 = 256, n3 = 256, lr = 0.001, batch_size = 256, beta_1 = 0.99, beta_2 = 0.999):\n",
    "    self.beta_1=beta_1\n",
    "    self.beta_2=beta_2\n",
    "    self.n1=n1\n",
    "    self.n2=n2\n",
    "    self.n3=n3\n",
    "    self.lr=lr\n",
    "    self.batch_size=batch_size\n",
    "\n",
    "  def fit(self, X_train, y, X_valid, y_valid):\n",
    "    \"\"\"Trains a model with the given parameters and given training set.\n",
    "    \n",
    "    Returns the trained model, embedded with its results.\n",
    "    \"\"\"\n",
    "    self.input_layer = Input(shape=(2048,))\n",
    "    # model = expand_dims(input_layer,axis=-1)\n",
    "    self.model = Dense(self.n1, kernel_initializer='normal', activation='relu')(self.input_layer) #(model)# Híperparâmetros [LSTM]: dropout, recurrent_dropout, número de nós\n",
    "    self.model = Dense(self.n2, kernel_initializer='normal', activation='relu')(self.model) # Híperparâmetros [DENSE]: Número de nós por camada\n",
    "    self.model = Dense(self.n3, kernel_initializer='normal', activation='relu')(self.model)\n",
    "    self.model = Dense(1, kernel_initializer='normal', activation='linear')(self.model)\n",
    "    self.model = keras.Model(inputs = self.input_layer, outputs = self.model)\n",
    "\n",
    "    adam = Adam(learning_rate = self.lr, beta_1=self.beta_1, beta_2=self.beta_2, epsilon = None, decay=0.01, amsgrad = False)\n",
    "    # Híperparâmetros [Adam]: lr, beta1, beta2, epsilon, decay\n",
    "\n",
    "    self.model.compile(loss = 'mse', optimizer= adam, metrics=['mae'],steps_per_execution=1,)\n",
    "\n",
    "    earlystopping = EarlyStopping(monitor='val_mae', mode='auto', verbose=0, patience=10, restore_best_weights=True)\n",
    "\n",
    "    # print(self.model.summary())\n",
    "    self.result = self.model.fit(\n",
    "                    X_train,\n",
    "                    y,\n",
    "                    batch_size=self.batch_size,\n",
    "                    epochs=48,\n",
    "                    callbacks=[earlystopping],\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    verbose=0\n",
    "                  )\n",
    "    del adam\n",
    "    del earlystopping\n",
    "    return self\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"Returns y_hat\"\"\"\n",
    "    return self.model.predict(X) # y_hat\n",
    "\n",
    "def product_dict(**kwargs):\n",
    "    \"\"\"Make the product of the settings therms.\"\"\"\n",
    "    import itertools\n",
    "    keys = kwargs.keys()\n",
    "    vals = kwargs.values()\n",
    "    for instance in itertools.product(*vals):\n",
    "        yield dict(zip(keys, instance))\n",
    "\n",
    "def my_iterable(config:dict, random_seed:int=None):\n",
    "    \"\"\"Generates and returns a sorted list of settings pairs, sorted randomly (with seed)\"\"\"\n",
    "    import random\n",
    "\n",
    "    if random_seed != None: random.seed(random_seed)\n",
    "\n",
    "    aux = list(product_dict(**config))\n",
    "    random.shuffle(aux)\n",
    "    return aux\n",
    "\n",
    "def my_accuracy(y_test,y_hat):\n",
    "  \"\"\"Returns a set of evaluation metrics of the output y_hat, in comparison to the real values y_test.\"\"\"\n",
    "  return {\n",
    "      'mae': mean_absolute_error(y_test,y_hat),\n",
    "      'mse': mean_squared_error(y_test,y_hat),\n",
    "      'mdae': median_absolute_error(y_test,y_hat),\n",
    "      'max_error': max_error(y_test,y_hat),\n",
    "      'r2_score': r2_score(y_test,y_hat)\n",
    "  }\n",
    "\n",
    "def nested(X,y,config={},n_iter:int=None,k:int=10):\n",
    "  N= 6\n",
    "  thetamin_vector = []\n",
    "  acc_vector = { # Note: you can comment this declaration if continuing from a partial result set\n",
    "      'mae': [],\n",
    "      'mse': [],\n",
    "      'mdae': [],\n",
    "      'max_error': [],\n",
    "      'r2_score': [],\n",
    "  }\n",
    "  # outer cross validation (k-fold)\n",
    "  cv_outer = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "  i=0\n",
    "  iterable_parameters = my_iterable(config=config,random_seed=123)[:n_iter]\n",
    "  if(n_iter!=None and n_iter == len(iterable_parameters)):\n",
    "    print('\\n',(k-N)*(n_iter*k+1),' models will be fitted\\n',sep='')\n",
    "  else:\n",
    "    print('\\n',(k-N)*(len(iterable_parameters)*k+1),' models will be fitted\\n',sep='')\n",
    "  print('------------------------------------------------\\n')\n",
    "\n",
    "  for tr_o, te_o in cv_outer.split(X):\n",
    "    i+=1\n",
    "    if i>N: # N is the last iteration the code successfully reported results\n",
    "      print('\\n[STARTED] OUTER_CV ',i,'/',k,sep='')\n",
    "      X_train_o, X_test_o = X[tr_o], X[te_o]\n",
    "      y_train_o, y_test_o = y[tr_o], y[te_o]\n",
    "      accmin=0.0\n",
    "      thetamin=None\n",
    "      j=0\n",
    "      for theta in iterable_parameters: #grid/random/hyperopt search\n",
    "        j+=1\n",
    "        print('\\nCurrent parameter configuration being tested [',j,'/',len(iterable_parameters),']:',sep='')\n",
    "        print(theta,'\\n',sep='')\n",
    "        acc=0.0\n",
    "        # inner cross validation (k-fold)\n",
    "        cv_inner=KFold(n_splits=k, shuffle=True, random_state=2)\n",
    "        l=0\n",
    "        for tr_i, te_i in tqdm(cv_inner.split(X_train_o)):\n",
    "          X_train_i, X_test_i = X_train_o[tr_i], X_train_o[te_i]\n",
    "          y_train_i, y_test_i = y_train_o[tr_i], y_train_o[te_i]\n",
    "\n",
    "          fit_params = {'X_valid': X_test_i, 'y_valid': y_test_i}\n",
    "          model_i=MyEstimator(**theta).fit(X_train_i,y_train_i,**fit_params) #fit\n",
    "          y_hat = model_i.predict(X_test_i)\n",
    "          y_hat = np.vectorize(lambda x: desNaNify(x))(y_hat)\n",
    "          print('\\n',y_hat[ ma.masked_invalid(y_hat)._mask ],' ; ',X_test_i[ ma.masked_invalid(X_test_i)._mask ],sep='',end='')\n",
    "          # evaluate the model\n",
    "          mse = mean_squared_error(y_test_i,y_hat)\n",
    "          acc+=mse\n",
    "          l+=1\n",
    "          print('\\nINNER_CV ',l,'/',k,' concluded',sep='')\n",
    "          del fit_params\n",
    "          del model_i\n",
    "          del y_hat\n",
    "          del mse\n",
    "          del X_train_i, X_test_i, y_train_i, y_test_i\n",
    "          del tr_i, te_i\n",
    "        # END OF INNER LOOP\n",
    "        print('HP RESULTS [',j,'/',len(iterable_parameters),']: ',acc,sep='')\n",
    "        if acc < accmin or j==1:\n",
    "          accmin = acc\n",
    "          thetamin = theta\n",
    "        del acc\n",
    "        del theta\n",
    "        del cv_inner\n",
    "        gc.collect()\n",
    "      # END OF RANDOMSEARCH LOOP\n",
    "      fit_params={'X_valid': X_test_o, 'y_valid': y_test_o}\n",
    "      model_o = MyEstimator(**thetamin).fit(X_train_o,y_train_o,**fit_params)\n",
    "      y_hat = model_o.predict(X_test_o)\n",
    "      aux=my_accuracy(y_test_o,y_hat)\n",
    "      for key in acc_vector.keys():\n",
    "        acc_vector[key].append(aux[key])\n",
    "      thetamin_vector.append(thetamin)\n",
    "      print('\\n[FINISHED] OUTER_CV ',i,'/',k,sep='')\n",
    "      print('Iteration Results:')\n",
    "      print(thetamin)\n",
    "      print(aux)\n",
    "      print('---------------------------------------')\n",
    "      del aux\n",
    "      del thetamin\n",
    "      del y_hat\n",
    "      del model_o\n",
    "      del fit_params\n",
    "      del X_train_o, X_test_o, y_test_o, y_train_o\n",
    "  # END OF OUTER LOOP\n",
    "  accfinal=dict()\n",
    "  for key in acc_vector.keys():\n",
    "    accfinal['mean_'+key]=np.mean(acc_vector[key])\n",
    "    if key in ['r2_score','mae','mse']:\n",
    "      accfinal['std_'+key]=np.std(acc_vector[key])\n",
    "  accfinal['train_results']=acc_vector\n",
    "  accfinal['thetas']=thetamin_vector\n",
    "  del acc_vector\n",
    "  del thetamin_vector\n",
    "  return accfinal\n",
    "# END OF NESTED FUNCTION\n",
    "\n",
    "X = np.asarray([np.asarray(x).astype('float32') for x in X])\n",
    "y = np.asarray(y).astype('float32')\n",
    "config = { # 2*5*2*9=180\n",
    "        'n1': [512], #2\n",
    "        'n2': [512], #1\n",
    "        'n3': [512], #1\n",
    "        \"lr\": [1e-5,1e-4,1e-3,1e-2], #5\n",
    "        \"batch_size\": [64,128], #2\n",
    "        \"beta_1\": [0.9,0.95,0.99], #3\n",
    "        \"beta_2\": [0.9,0.99,0.999], #3\n",
    "      }\n",
    "results = nested(X,y,\n",
    "                 config=config,\n",
    "                 n_iter=100,\n",
    "                 k=10)\n",
    "print('\\n------------------------------------------\\nNESTED CV RESULTS:',results,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bw_3Ni6a2ld9"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%d%m%y-%H%M\")\n",
    "\n",
    "with open(f'results-{current_time}.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('\\nThe results were been written to a results.pckl file!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands to open results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vg5xDTa6RoAS",
    "outputId": "43f66ff6-6042-4cee-a8c3-1d33a2829fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n1': 256}\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install pickle5 --quiet\n",
    "# import pickle5 as pickle\n",
    "# with open('results-ddmmyyyy-HHMM.pickle', 'rb') as handle:\n",
    "#   unserialized_data = pickle.load(handle)\n",
    "# print(unserialized_data['thetas'][0])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
